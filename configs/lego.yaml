seed: 4
exp_name: 'lego'
#train:
root_dir: 'D:\\NeRF\\datasets\\data\\nerf_synthetic\\lego'
dataset_name: 'blender'
img_wh: [800, 800]
spheric_poses: False # whether images are taken in spheric poses (for llff)
N_samples: 64  # number of coarse samples
N_importance: 128 # number of additional fine samples
use_disp: False  # use disparity depth sampling
perturb: 1.0  # factor to perturb depth sampling points
noise_std: 1.0  # std dev of noise added to regularize sigma
batch_size: 1024
chunk: 32768 #  32*1024   chunk size to split the input to avoid OOM
num_epochs: 16
num_gpus: 1
ckpt_path: None  # pretrained checkpoint path to load
prefixes_to_ignore: ['loss']  # the prefixes to ignore in the checkpoint state dict
#val:
#batch_size: 1
#batch_type: 'single_image'  # For "single_image", the batch must set to 1
#num_work: 4
#randomized: False
#white_bkgd: True
#check_interval: 10000
#chunk_size: 8192  # The amount of input rays in a forward propagation
#sample_num: 4  # Total number of images verified during once validation
#nerf:
#num_samples: 128  # The number of samples per level.
#num_levels: 2  # The number of sampling levels.
#resample_padding: 0.01  # Dirichlet/alpha "padding" on the histogram.
#stop_resample_grad: True  # If True, don't backprop across levels')
#use_viewdirs: True  # If True, use view directions as a condition.
#disparity: False  # If True, sample linearly in disparity, not in depth.
#ray_shape: 'cone'  # The shape of cast rays ('cone' or 'cylinder').
#min_deg_point: 0  # Min degree of positional encoding for 3D points.
#max_deg_point: 16  # Max degree of positional encoding for 3D points.
#deg_view: 4  # Degree of positional encoding for viewdirs.
#density_activation: 'softplus'  # Density activation.
#density_noise: 0.  # Standard deviation of noise added to raw density.
#density_bias: -1.  # The shift added to raw densities pre-activation.
#rgb_activation: 'sigmoid'  # The RGB activation.
#rgb_padding: 0.001  # Padding added to the RGB outputs.
#disable_integration: False  # If True, use PE instead of IPE.
#append_identity: Ture  # If True, append original view direction features
#  #mlp:
#net_depth: 8  # The depth of the first part of MLP.
#net_width: 256  # The width of the first part of MLP.
#net_depth_condition: 1  # The depth of the second part of MLP.
#net_width_condition: 128  # The width of the second part of MLP.
#net_activation: 'relu'  # The activation function.
#skip_index: 4  # Add a skip connection to the output of every N layers.
#num_rgb_channels: 3  # The number of RGB channels.
#num_density_channels: 1  # The number of density channels.
#optimizer:
optimizer: 'adam' # choices=['sgd', 'adam', 'radam', 'ranger']
lr: 5e-4
weight_decay: 0  # weight decay
lr_scheduler: steplr  # choices=['steplr', 'cosine', 'poly']
warmup_multiplier: 1.0 # Gradually warm-up(increasing) learning rate in optimizer
#loss:
loss_type: mse
coarse_loss_mult: 0.1
decay_step: [20]  # scheduler decay step
decay_gamma: 0.1 # learning rate decay amount
poly_exp: 0.9  # exponent for polynomial learning rate decay